{
 "cells": [
  {
   "cell_type": "raw",
   "id": "68d02efa",
   "metadata": {},
   "source": [
    "Create Manual Schema\n",
    "possible interview questions\n",
    "\n",
    "1. How to create schema in pyspark?\n",
    "2. what are other way to create it?\n",
    "3. what is StructField and StructType in the Schema?\n",
    "4. what if I have header in my data?\n",
    "\n",
    "Schema\n",
    "1. StructField and StructType\n",
    "2. DDL\n",
    "\n",
    "we need to import First:\n",
    "\n",
    "from pyspark.sql.types import StructField, StructType\n",
    "\n",
    "my_schema = StructType([\n",
    "                        StructField(\"ID\",IntegerType(), True)\n",
    "                        StructField(\"Name\",StringType(), True)\n",
    "                        StructField(\"Age\",IntegerType(), True)\n",
    "])\n",
    "\n",
    "ddl_my_schema = \" ID Integer, Name String, Age Integer\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03dd122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Sample\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b4a8528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|              _c0|                _c1|  _c2|\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "|    United States|              India|   69|\n",
      "|            Egypt|      United States|   24|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flight = spark.read.format('csv')\\\n",
    "            .option('header' , 'false')\\\n",
    "            .option('inferSchema', 'false')\\\n",
    "            .option('mode', 'Permissive')\\\n",
    "            .load('2010-summary.csv')\n",
    "\n",
    "df_flight.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c7d03e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, IntegerType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6beee09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_schema = StructType([\n",
    "            StructField('DEST_COUNTRY_NAME',StringType(), True),\n",
    "            StructField('ORIGIN_COUNTRY_NAME',StringType(), True),\n",
    "            StructField('count',IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2be5dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| NULL|\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "|    United States|              India|   69|\n",
      "|            Egypt|      United States|   24|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flight = spark.read.format('csv')\\\n",
    "            .option('header' , 'false')\\\n",
    "            .option('inferSchema', 'false')\\\n",
    "            .schema(my_schema)\\\n",
    "            .option('mode', 'Permissive')\\\n",
    "            .load('2010-summary.csv')\n",
    "\n",
    "df_flight.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d19f9f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "|    United States|              India|   69|\n",
      "|            Egypt|      United States|   24|\n",
      "|Equatorial Guinea|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flight = spark.read.format('csv')\\\n",
    "            .option('header' , 'true')\\\n",
    "            .option('inferSchema', 'false')\\\n",
    "            .schema(my_schema)\\\n",
    "            .load('2010-summary.csv')\n",
    "\n",
    "df_flight.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "077a2daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flight.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97c2790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d639ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
